{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNR351ge7Qb9"
      },
      "source": [
        "# Transfer learning & fine-tuning\n",
        "by uramoon@kw.ac.kr<br><br>\n",
        "\n",
        "Xception을 사용하여 고양이와 개를 분류해봅시다.<br>\n",
        "런타임 유형은 가급적 GPU로 설정하세요. (CPU도 가능)<br><br>\n",
        "\n",
        "**Author:** [fchollet](https://twitter.com/fchollet)<br>\n",
        "**Date created:** 2020/04/15<br>\n",
        "**Last modified:** 2020/05/12<br>\n",
        "**Description:** Complete guide to transfer learning & fine-tuning in Keras.<br>\n",
        "(<a href=\"https://raw.githubusercontent.com/ronreiter/interactive-tutorials/master/LICENSE\">Apache 2.0 License</a>)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EseCFXYV7QcA"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yfI7THmn7QcA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nm0AGWSs7QcB"
      },
      "source": [
        "## 소개\n",
        "\n",
        "**전이 학습**은 어떤 문제에 대해 학습된 특징들을 새로운 문제의 풀이에 사용하는 것을 뜻합니다. <br>예를 들면, 라쿤을 인식하는 모델에서 사용되는 특징들로 너구리를 인식하는 데 사용할 수 있을 것입니다.<br>\n",
        "\n",
        "<img src=\"https://extension.umd.edu/sites/extension.umd.edu/files/styles/optimized/public/2021-02/hgic_veg_wildlife_raccoon.jpg?itok=p4k_Z_CF\" height=\"200\"><figcaption>라쿤 사진 출처: https://extension.umd.edu/resource/raccoons</figcaption>\n",
        "\n",
        "<img src=\"https://image-notepet.akamaized.net/resize/620x-/seimage/20171108%2Fe6d1ec360a4ab04e21e580882d9c989e.jpg\" height=\"200\"><figcaption>너구리 사진 출처: https://www.notepet.co.kr/news/article/article_view/?idx=10434</figcaption>\n",
        "\n",
        "전이학습은 다음의 수행절차를 갖습니다.\n",
        "1. 기존에 훈련된 모델을 가져온다.\n",
        "2. 가져온 모델을 훈련이 불가능하도록 설정한다. (가중치들을 고정시킴)\n",
        "3. 가져온 모델에 몇 개의 층을 추가한다.\n",
        "4. 내가 추가한 층만 나의 데이터로 훈련시킨다.\n",
        "\n",
        "추가적으로 고정시킨 모델을 훈련 가능하도록 설정해 세부 튜닝을 시도할 수도 있습니다.\n",
        "\n",
        "This is adapted from\n",
        "[Deep Learning with Python](https://www.manning.com/books/deep-learning-with-python)\n",
        " and the 2016 blog post\n",
        "[\"building powerful image classification models using very little\n",
        " data\"](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MHi_AVw7QcI"
      },
      "source": [
        "## 데이터 가져오기\n",
        "원래 25,000장의 그림이 있는데 15,000장만 가져와서 그 중 10,000장은 훈련, 2500장은 검증, 2500장은 테스트에 사용하겠습니다.<br>\n",
        "(오염된 이미지들이 있어서 다 받아오진 못하고 수 백장의 사진이 걸러집니다.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "MvBpIk2u7QcI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d0b7b8a-5573-4fdc-f1d7-3f5b94ab7d64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to /root/tensorflow_datasets/cats_vs_dogs/4.0.0...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:1738 images were corrupted and were skipped\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset cats_vs_dogs downloaded and prepared to /root/tensorflow_datasets/cats_vs_dogs/4.0.0. Subsequent calls will reuse this data.\n",
            "Number of training samples: 9305\n",
            "Number of validation samples: 2326\n",
            "Number of test samples: 2326\n"
          ]
        }
      ],
      "source": [
        "import tensorflow_datasets as tfds\n",
        "\n",
        "tfds.disable_progress_bar()\n",
        "\n",
        "# 임시 코드 (다운로드가 안되면 지우세요.)\n",
        "setattr(tfds.image_classification.cats_vs_dogs, '_URL',\"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip\")\n",
        "\n",
        "train_ds, validation_ds, test_ds = tfds.load(\n",
        "    \"cats_vs_dogs\",\n",
        "    # Reserve 10% for validation and 10% for test\n",
        "    split=[\"train[:40%]\", \"train[40%:50%]\", \"train[50%:60%]\"],\n",
        "    as_supervised=True,  # Include labels\n",
        ")\n",
        "\n",
        "print(\"Number of training samples: %d\" % tf.data.experimental.cardinality(train_ds))\n",
        "print(\n",
        "    \"Number of validation samples: %d\" % tf.data.experimental.cardinality(validation_ds)\n",
        ")\n",
        "print(\"Number of test samples: %d\" % tf.data.experimental.cardinality(test_ds))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TODO1: 데이터셋 전처리하기"
      ],
      "metadata": {
        "id": "1X1NIOLN_u6L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 데이터셋의 크기 변경하기\n",
        "size = (150, 150)\n",
        "\n",
        "train_ds = train_ds.map(lambda x, y: (tf.image.resize(x, size), y))\n",
        "validation_ds = validation_ds.map(lambda x, y: (tf.image.resize(x, size), y))\n",
        "test_ds = test_ds.map(lambda x, y: (tf.image.resize(x, size), y))"
      ],
      "metadata": {
        "id": "kQSbgHOW_0g-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Xception의 전처리 기법 적용하기\n",
        "from tensorflow.keras.applications.xception import Xception\n",
        "from tensorflow.keras.applications.xception import preprocess_input\n",
        "\n",
        "train_ds = train_ds.map(lambda x, y: (preprocess_input(tf.image.resize(x, size)), y))\n",
        "validation_ds = validation_ds.map(lambda x, y: (preprocess_input(tf.image.resize(x, size)), y))\n",
        "test_ds = test_ds.map(lambda x, y: (preprocess_input(tf.image.resize(x, size)), y))\n"
      ],
      "metadata": {
        "id": "uTwL6NIE_-3l"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋을 32장씩 묶읍시다.\n",
        "batch_size = 32\n",
        "\n",
        "train_ds = train_ds.cache().batch(batch_size).prefetch(buffer_size=10)\n",
        "validation_ds = validation_ds.cache().batch(batch_size).prefetch(buffer_size=10)\n",
        "test_ds = test_ds.cache().batch(batch_size).prefetch(buffer_size=10)"
      ],
      "metadata": {
        "id": "A5WzWUapAcVd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhtbx3Xq7QcK"
      },
      "source": [
        "## TODO2: 데이터 증강 층 만들기<br>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "cFmmTjHU7QcK"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
        "        layers.experimental.preprocessing.RandomRotation(0.1),\n",
        "        layers.experimental.preprocessing.RandomZoom(0.1),\n",
        "    ]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vZcwfo47QcK"
      },
      "source": [
        "## TODO3: 모델 정의하기\n",
        "\n",
        "가져온 모델 앞에 입력층과 데이터 층강층을 추가하고 뒤에 예측하는 부분 (MLP와 같은 Dense층) 을 추가합니다."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "base_model = keras.applications.Xception(\n",
        "    weights=\"imagenet\", # ImageNet에 대해서 훈련된 모델을 가져옵니다.\n",
        "    input_shape=(150, 150, 3),\n",
        "    include_top=False,  # ImageNet 데이터를 예측하는 출력층은 포함하지 않습니다.\n",
        ")  \n",
        "# Xception은 훈련이 불가능하도록 설정합니다.\n",
        "base_model.trainable = False\n",
        "\n",
        "model = models.Sequential()\n",
        "\n",
        "#TODO: 입력층 추가\n",
        "model.add(layers.Input(shape=(150, 150, 3)))\n",
        "\n",
        "#TODO: 데이터 증강층 추가\n",
        "model.add(data_augmentation)\n",
        "#가져온 모델 추가\n",
        "model.add(base_model)\n",
        "\n",
        "# MLP는 일차원으로 펼쳐진 입력이 필요합니다. \n",
        "# 아래 둘 중 원하는 것 하나만 쓰세요.\n",
        "# Xception은 5 x 5 사이즈의 2048개 채널을 출력합니다.\n",
        "#model.add(layers.Flatten()) # 각 채널의 모든 픽셀들을 일차원으로 이어붙이는 무식하고 낡은 방법 (25개 x 2048장)\n",
        "#model.add(layers.GlobalAveragePooling2D()) # 각 5 x 5 채널을 하나의 값으로 요약한 후 일차원으로 이어붙이는 방법 (2048개)\n",
        "\n",
        "# 출력층 추가 (0~1 출력하는 노드 하나만 필요하고 적절한 활성화 함수 기재)\n",
        "model.add(layers.GlobalAveragePooling2D())\n",
        "model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
        "# 컴파일\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]) "
      ],
      "metadata": {
        "id": "AoJ0jaoUCKpI"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 직접 만들었던 모델과 비교해보세요.\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "ysKY9a2VDzPP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2d01d81-13e9-4494-c803-be5e3a548421"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " sequential_5 (Sequential)   (None, 150, 150, 3)       0         \n",
            "                                                                 \n",
            " xception (Functional)       (None, 5, 5, 2048)        20861480  \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 2048)             0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 2049      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,863,529\n",
            "Trainable params: 2,049\n",
            "Non-trainable params: 20,861,480\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_9fLIML7QcL"
      },
      "source": [
        "## TODO4: 훈련하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "OjvNyH3y7QcL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45f868c6-af24-49dd-fd49-b5362afdf97a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10000\n",
            "291/291 [==============================] - 40s 85ms/step - loss: 0.1723 - accuracy: 0.9280 - val_loss: 0.0789 - val_accuracy: 0.9721\n",
            "Epoch 2/10000\n",
            "291/291 [==============================] - 22s 74ms/step - loss: 0.1261 - accuracy: 0.9444 - val_loss: 0.0771 - val_accuracy: 0.9695\n",
            "Epoch 3/10000\n",
            "291/291 [==============================] - 22s 76ms/step - loss: 0.1167 - accuracy: 0.9493 - val_loss: 0.0740 - val_accuracy: 0.9699\n",
            "Epoch 4/10000\n",
            "291/291 [==============================] - 22s 75ms/step - loss: 0.1159 - accuracy: 0.9541 - val_loss: 0.0803 - val_accuracy: 0.9686\n",
            "Epoch 5/10000\n",
            "291/291 [==============================] - 22s 76ms/step - loss: 0.1038 - accuracy: 0.9556 - val_loss: 0.0725 - val_accuracy: 0.9703\n",
            "Epoch 6/10000\n",
            "291/291 [==============================] - 22s 76ms/step - loss: 0.1026 - accuracy: 0.9591 - val_loss: 0.0705 - val_accuracy: 0.9729\n",
            "Epoch 7/10000\n",
            "291/291 [==============================] - 23s 79ms/step - loss: 0.1048 - accuracy: 0.9586 - val_loss: 0.0735 - val_accuracy: 0.9699\n",
            "Epoch 8/10000\n",
            "291/291 [==============================] - 22s 76ms/step - loss: 0.1020 - accuracy: 0.9597 - val_loss: 0.0711 - val_accuracy: 0.9712\n",
            "Epoch 9/10000\n",
            "291/291 [==============================] - 22s 76ms/step - loss: 0.1043 - accuracy: 0.9563 - val_loss: 0.0736 - val_accuracy: 0.9695\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0a102a4430>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "# TODO: 자유롭게 설정하세요.\n",
        "epochs = 10000\n",
        "es = EarlyStopping(patience=3, restore_best_weights=True)\n",
        "model.fit(train_ds, epochs=epochs, callbacks=es, validation_data=validation_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 테스트 데이터로 평가해보기"
      ],
      "metadata": {
        "id": "Arcvlsa_Ge7p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_ds)"
      ],
      "metadata": {
        "id": "xwHixM5yGhIJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f595ccf-f89a-4616-a59d-d6f680576509"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73/73 [==============================] - 4s 58ms/step - loss: 0.0705 - accuracy: 0.9738\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.07049636542797089, 0.9737747311592102]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FW0TLL%2FbtqRx0uGeC2%2FKxbOgpwhzXXvwu1VtcmjNK%2Fimg.jpg' height=200>"
      ],
      "metadata": {
        "id": "e7MyLKdpGhug"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qA2QpMBl7QcL"
      },
      "source": [
        "## 세부 튜닝하기\n",
        "\n",
        "가져온 모델인 Xception까지 우리 데이터에 맞게 훈련해봅시다.<br>\n",
        "너무 많은 시간이 소요될 수 있으니 적당히 수행합니다. (중간에 중단 버튼 눌러도 괜찮음)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "WSBAgWEj7QcL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d5ab336-9892-4352-a60f-ef4d7a3b3b49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " sequential_5 (Sequential)   (None, 150, 150, 3)       0         \n",
            "                                                                 \n",
            " xception (Functional)       (None, 5, 5, 2048)        20861480  \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 2048)             0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 2049      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,863,529\n",
            "Trainable params: 20,809,001\n",
            "Non-trainable params: 54,528\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "291/291 [==============================] - 103s 234ms/step - loss: 0.2608 - accuracy: 0.9005 - val_loss: 0.3142 - val_accuracy: 0.9003\n",
            "Epoch 2/100\n",
            "291/291 [==============================] - 68s 235ms/step - loss: 0.1460 - accuracy: 0.9411 - val_loss: 0.1241 - val_accuracy: 0.9549\n",
            "Epoch 3/100\n",
            "291/291 [==============================] - 69s 238ms/step - loss: 0.1069 - accuracy: 0.9592 - val_loss: 0.1667 - val_accuracy: 0.9458\n",
            "Epoch 4/100\n",
            "291/291 [==============================] - 69s 239ms/step - loss: 0.0983 - accuracy: 0.9608 - val_loss: 0.1192 - val_accuracy: 0.9579\n",
            "Epoch 5/100\n",
            "291/291 [==============================] - 70s 240ms/step - loss: 0.0841 - accuracy: 0.9689 - val_loss: 0.0974 - val_accuracy: 0.9613\n",
            "Epoch 6/100\n",
            "291/291 [==============================] - 69s 238ms/step - loss: 0.0856 - accuracy: 0.9687 - val_loss: 0.1794 - val_accuracy: 0.9488\n",
            "Epoch 7/100\n",
            "291/291 [==============================] - 69s 239ms/step - loss: 0.0727 - accuracy: 0.9737 - val_loss: 0.0883 - val_accuracy: 0.9669\n",
            "Epoch 8/100\n",
            "291/291 [==============================] - 69s 239ms/step - loss: 0.0665 - accuracy: 0.9756 - val_loss: 0.2745 - val_accuracy: 0.9114\n",
            "Epoch 9/100\n",
            "291/291 [==============================] - 69s 239ms/step - loss: 0.0592 - accuracy: 0.9773 - val_loss: 0.1904 - val_accuracy: 0.9355\n",
            "Epoch 10/100\n",
            "291/291 [==============================] - 70s 239ms/step - loss: 0.0596 - accuracy: 0.9778 - val_loss: 0.0949 - val_accuracy: 0.9660\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0a095c5fc0>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# 가져온 모델 훈련 가능하도록 설정\n",
        "base_model.trainable = True\n",
        "\n",
        "# 훈련 가능한 파라미터 수를 위와 비교해보세요.\n",
        "model.summary()\n",
        "\n",
        "# 컴파일 해주세요.\n",
        "optimizer = keras.optimizers.Adam(lr=1e-5)\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "# 방금 훈련한 모델을 조금 더 훈련시킵니다.\n",
        "epochs = 100\n",
        "model.fit(train_ds, epochs=epochs, callbacks=es, validation_data=validation_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1x3KXtZY7QcL"
      },
      "source": [
        "## 다시 테스트 데이터로 평가해보기"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_ds)"
      ],
      "metadata": {
        "id": "Phq2K78YL9E6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7817175-c508-4b5e-f971-43438b433f24"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73/73 [==============================] - 5s 63ms/step - loss: 0.0994 - accuracy: 0.9652\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.09942273795604706, 0.9651762843132019]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "적은 시간을 사용했을 경우 오히려 성능이 떨어질 가능성이 높습니다.<br>\n",
        "원본 노트북에서는 훈련 불가능하게 만든 상태에서 20 epochs, 세부 튜닝에서 10 epochs 훈련하는데 성능이 조금 좋아집니다.<br>\n",
        "전이학습에서 세부 튜닝하는 방법까지 공부한 것에 의의를 둡시다."
      ],
      "metadata": {
        "id": "TYMX7_kXMETZ"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}